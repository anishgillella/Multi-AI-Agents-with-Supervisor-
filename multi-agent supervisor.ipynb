{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 179, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 136, in resolve\n",
      "    elif installed_dist.version != candidate.version:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py\", line 175, in version\n",
      "    return parse_version(self._dist.version)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 200, in __init__\n",
      "    match = self._regex.search(version)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached langgraph-0.2.44-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.16)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.7)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain_experimental\n",
      "  Using cached langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langsmith in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.131)\n",
      "Collecting langsmith\n",
      "  Using cached langsmith-0.1.139-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
      "  Using cached langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.0.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
      "  Using cached langgraph_sdk-0.1.35-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting openai<2.0.0,>=1.52.0 (from langchain_openai)\n",
      "  Using cached openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
      "  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.5.14)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anish\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anish\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai<2.0.0,>=1.52.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph langchain langchain_openai langchain_experimental langsmith pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 0.2.44\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://www.github.com/langchain-ai/langgraph\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-sdk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def set_api_key(var: str):\n",
    "    os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "# Prompt for API keys every time\n",
    "set_api_key(\"OPENAI_API_KEY\")\n",
    "set_api_key(\"TAVILY_API_KEY\")\n",
    "set_api_key(\"LANGCHAIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi Agent\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cREATE TOOLS - ONE TOOL FOR SEARCH ENGINE IN A WEB SEARCH , ONE TO CREATE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results = 5)\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function\n",
    "To convert the agent response to human message which is  to add to the global state of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state,agent,name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content = result[\"messages\"][-1].content,name = name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Agent Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Researcher\",\"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \"following workers : {members}. Given the following user request,\"\n",
    "    \"respond with the worker to act next. Each worker will perform a\"\n",
    "    \"task and respond with their results and status. When finished,\"\n",
    "    \"respond with FINISH.\"\n",
    ")\n",
    "\n",
    "#Our team supervisor is an LLM node. It just picks the next agent to process and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt  = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        MessagesPlaceholder(variable_name = \"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \"Or should we FINISH? Select one of {options}\",\n",
    "        ),\n",
    "    ],\n",
    "    ).partial(options = str(options),members = \", \".join(members))\n",
    "\n",
    "llm =ChatOpenAI(model = \"gpt-4o\")\n",
    "\n",
    "def supervisor_Agent(state):\n",
    "    supervisor_chain = prompt|llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Graph\n",
    "Defining the worker nodes using the function we defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x124eae2ad10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools \n",
    "import operator\n",
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "# The annotation tells the graph that new messages will always be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage],operator.add]\n",
    "    # The next field indicates where to route next\n",
    "    next: str\n",
    "\n",
    "research_agent = create_react_agent(llm, tools = [tavily_tool])\n",
    "research_node = functools.partial(agent_node, agent = research_agent, name = \"Researcher\")\n",
    "\n",
    "code_agent = create_react_agent(llm, tools = [python_repl_tool])\n",
    "code_node = functools.partial(agent_node, agent = code_agent, name = \"Coder\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\",research_node) \n",
    "workflow.add_node(\"Coder\",code_node)\n",
    "workflow.add_node(\"supervisor\",supervisor_Agent)                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting all the Edges in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    #Since we always want the agents workers to report back to the supervisor when done\n",
    "    workflow.add_edge(member,\"supervisor\")\n",
    "#The supervisor will then decide who to route to next or to finish it\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "if \"supervisor\" not in workflow.branches:\n",
    "    workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.add_edge(START,\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n",
      "{'Coder': {'messages': [HumanMessage(content='Here\\'s the code to print \"Hello, World!\" to the terminal:\\n\\n```python\\nprint(\\'Hello, World!\\')\\n```\\n\\nWhen executed, it produces the output:\\n\\n```\\nHello, World!\\n```', additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "### Invoke the team\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\"\n",
    ": [\n",
    "    HumanMessage(content = \"code hello world and print it to the terminal\")\n",
    "]   }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content=\"### Research Report on Claude Models\\n\\n#### Overview\\nClaude models are a family of large language models (LLMs) developed by Anthropic, an AI research and safety company based in San Francisco. These models are designed to excel in general, open-ended conversation, search, writing, editing, outlining, and various forms of text classification applications.\\n\\n#### Claude 2\\nClaude 2 was introduced earlier in 2023 and is noted for its capabilities in automating a wide variety of text classification tasks. It serves as a robust pre-trained model that offers a strong foundation for developing further AI solutions. The training data for Claude 2 is current up to early 2023, with about 10% dedicated to research-specific content. This model has been evaluated for safety, alignment, and capabilities, ensuring it meets high standards of performance and ethical use.\\n\\n#### Claude 3 Model Family\\nThe Claude 3 model family, consisting of Claude 3 Opus, Claude 3 Sonnet, and Claude 3 Haiku, represents a new generation of multimodal models. Each variant is tailored for different needs:\\n- **Claude 3 Opus**: The most capable model in the family, designed for comprehensive tasks.\\n- **Claude 3 Sonnet**: Balances skills and speed, making it versatile for various applications.\\n- **Claude 3 Haiku**: The fastest and most cost-effective model, suitable for applications where speed is crucial.\\n\\nThese models have been subject to in-depth evaluations concerning their core capabilities, safety, societal impacts, and potential risks, in alignment with Anthropic's Responsible Scaling Policy.\\n\\n#### Intended Uses and Applications\\nClaude models are primarily utilized for:\\n- Enhancing conversational AI capabilities.\\n- Facilitating research and development in AI-driven writing and editing.\\n- Supporting complex text classification projects.\\n- Ensuring safe and aligned AI interactions across different domains.\\n\\n#### Conclusion\\nClaude models, particularly the Claude 2 and Claude 3 families, embody significant advancements in AI model design and implementation. With their emphasis on safety and alignment, these models are positioned to contribute positively to AI applications across industries, ensuring both utility and ethical integrity in AI interactions.\", additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n",
      "{'Coder': {'messages': [HumanMessage(content=\"Certainly! Here's a brief research report on Claude models:\\n\\n---\\n\\n### Research Report on Claude Models\\n\\n#### Introduction\\nClaude models are a series of advanced language models developed by Anthropic, a company focused on AI safety and research. These models are designed to facilitate a broad range of applications in natural language processing, including conversational AI, text classification, and content generation.\\n\\n#### Development and Versions\\nThe Claude models have evolved over time, with notable improvements in capabilities and safety measures:\\n\\n1. **Claude 2**: Launched in early 2023, Claude 2 is a pre-trained model that excels in automating text classification tasks. It is built on a vast dataset, with a significant portion dedicated to research-specific content, and is engineered to ensure high performance in both capabilities and ethical considerations.\\n\\n2. **Claude 3 Model Family**: This family includes Claude 3 Opus, Claude 3 Sonnet, and Claude 3 Haiku, each tailored for specific needs:\\n   - **Claude 3 Opus**: Offers the most comprehensive capabilities within the family.\\n   - **Claude 3 Sonnet**: Balances performance and speed for versatile applications.\\n   - **Claude 3 Haiku**: Prioritizes speed and cost-effectiveness, ideal for scenarios where quick responses are essential.\\n\\nThe Claude 3 models are multimodal, meaning they can handle more than just text, and have undergone rigorous evaluations for safety, societal impact, and alignment with ethical AI practices.\\n\\n#### Applications\\nClaude models are versatile and can be applied in various domains, including:\\n- **Conversational AI**: Enhancing user interaction through natural language dialogues.\\n- **Text Classification**: Automating and refining the categorization of text-based data.\\n- **Content Creation and Editing**: Assisting in drafting, editing, and organizing written content.\\n- **Research and Development**: Supporting AI-driven innovation in various fields.\\n\\n#### Conclusion\\nClaude models represent a significant stride in AI development, emphasizing both functionality and safety. With their robust capabilities and alignment with ethical standards, these models are well-suited for diverse applications, promising improvements in how AI interacts with and aids human activities across multiple sectors.\\n\\n--- \\n\\nThis report provides a snapshot of the Claude models, their development, capabilities, and applications, highlighting their role in advancing AI technology responsibly.\", additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content = \"Write a brief research report on Claude models\")]},\n",
    "    {\"recursion_limit\": 10},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
